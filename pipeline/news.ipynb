{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 337,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 337,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "import os\n",
    "import requests\n",
    "from dotenv import load_dotenv\n",
    "import openai\n",
    "from geopy.distance import geodesic\n",
    "import xml.etree.ElementTree as ET\n",
    "from datetime import datetime\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [],
   "source": [
    "BING_KEY = os.environ[\"BING_SEARCH_V7_SUBSCRIPTION_KEY\"]\n",
    "BING_API_ENDPOINT = os.environ[\"BING_SEARCH_V7_ENDPOINT\"]\n",
    "OPENAI_API_KEY = os.environ[\"OPENAI_API_KEY\"]\n",
    "MODEL_ID = \"gpt-3.5-turbo-1106\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_news(query=\"\", count=100):\n",
    "    headers = {\"Ocp-Apim-Subscription-Key\": BING_KEY}\n",
    "    params = {\"mkt\": \"en-US\", \"q\": query, \"count\": count, \"sortBy\": \"Date\"}\n",
    "    response = requests.get(BING_API_ENDPOINT, headers=headers, params=params)\n",
    "    response.raise_for_status()\n",
    "    news_articles = response.json()\n",
    "    return news_articles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Specify queries for each location\n",
    "Queries contain:\n",
    "- The location's country, city and coordinates\n",
    "- Events to search for in each location\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {},
   "outputs": [],
   "source": [
    "QUERIES = [\n",
    "    {\n",
    "        \"location\": {\n",
    "            \"country\": \"Colombia\",\n",
    "            \"city\": \"Bogota\",\n",
    "            \"coordinates\": [4.678390790414742, -74.08310452775451],\n",
    "        },\n",
    "        \"events\": [\n",
    "            \"natural disaster\",\n",
    "            \"workers strike\",\n",
    "        ],\n",
    "    },\n",
    "    {\n",
    "        \"location\": {\n",
    "            \"country\": \"Guatemala\",\n",
    "            \"city\": \"El Estor\",\n",
    "            \"coordinates\": [15.5322197047923, -89.33265507494376],\n",
    "        },\n",
    "        \"events\": [\n",
    "            \"natural disaster\",\n",
    "            \"workers strike\",\n",
    "        ],\n",
    "    },\n",
    "    {\n",
    "        \"location\": {\n",
    "            \"country\": \"Brazil\",\n",
    "            \"city\": \"Onca Puma\",\n",
    "            \"coordinates\": [-6.605335306591729, -51.100066887737015],\n",
    "        },\n",
    "        \"events\": [\n",
    "            \"natural disaster\",\n",
    "            \"workers strike\",\n",
    "        ],\n",
    "    },\n",
    "    {\n",
    "        \"location\": {\n",
    "            \"country\": \"Holland\",\n",
    "            \"city\": \"Terneuzen\",\n",
    "            \"coordinates\": [51.33013942257549, 3.83565678442852],\n",
    "        },\n",
    "        \"events\": [\n",
    "            \"natural disaster\",\n",
    "            \"workers strike\",\n",
    "        ],\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fetch articles from news api (expensive cell ðŸ¥²)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 414 articles\n"
     ]
    }
   ],
   "source": [
    "ALL_ARTICLES = []\n",
    "\n",
    "for query in QUERIES:\n",
    "    for event in query[\"events\"]:\n",
    "        country = query[\"location\"][\"country\"]\n",
    "        city = query[\"location\"][\"city\"]\n",
    "        q = f\"{event} {city} {country}\"\n",
    "        news_articles = get_news(query=q)\n",
    "        for article in news_articles[\"value\"]:\n",
    "           ALL_ARTICLES.append(\n",
    "               {\n",
    "                    \"location\": query[\"location\"],\n",
    "                    \"event\": event,\n",
    "                    \"name\": article[\"name\"],\n",
    "                    \"url\": article[\"url\"],\n",
    "                    \"description\": article[\"description\"],\n",
    "                    \"timestamp\": article[\"datePublished\"]\n",
    "                }\n",
    "            )\n",
    "\n",
    "print(f\"Found {len(ALL_ARTICLES)} articles\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {},
   "outputs": [],
   "source": [
    "json.dump(ALL_ARTICLES, open(\"data/full-news-data.json\", \"w\"), indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fetch distaster geodata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 448,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_distance(lat1, lon1, lat2, lon2):\n",
    "    coords1 = (lat1, lon1)\n",
    "    coords2 = (lat2, lon2)\n",
    "    return geodesic(coords1, coords2).kilometers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 449,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_xml(content_xml, locations, url):\n",
    "    root = ET.fromstring(content_xml)\n",
    "    result_data = []\n",
    "    for item in root.findall('.//item'):\n",
    "        title = item.find('./title').text\n",
    "        description = item.find('./description').text\n",
    "        pub_date_raw = item.find('./pubDate').text\n",
    "        date = datetime.strptime(pub_date_raw, \"%a, %d %b %Y %H:%M:%S %Z\").strftime(\"%Y-%m-%dT%H:%M:%SZ\")\n",
    "        point = item.find('.//geo:Point', namespaces={'geo': 'http://www.w3.org/2003/01/geo/wgs84_pos#'})\n",
    "        event_lat = point.find('./geo:lat', namespaces={'geo': 'http://www.w3.org/2003/01/geo/wgs84_pos#'}).text\n",
    "        event_lon = point.find('./geo:long', namespaces={'geo': 'http://www.w3.org/2003/01/geo/wgs84_pos#'}).text\n",
    "        alert_level = item.find('./gdacs:alertlevel', namespaces={'gdacs': 'http://www.gdacs.org'}).text\n",
    "        # alert_score = item.find('./gdacs:alertscore', namespaces={'gdacs': 'http://www.gdacs.org'}).text\n",
    "        # calculation_type = item.find('./gdacs:calculationtype', namespaces={'gdacs': 'http://www.gdacs.org'}).text\n",
    "        # severity_level = item.find('./gdacs:severity', namespaces={'gdacs': 'http://www.gdacs.org'}).get('value')\n",
    "        # country = item.find('./gdacs:country', namespaces={'gdacs': 'http://www.gdacs.org'}).text\n",
    "\n",
    "        result_json = {\n",
    "            \"title\": title,\n",
    "            \"description\": description,\n",
    "            \"timestamp\": date,\n",
    "            \"locations_affected\": [],\n",
    "            \"url\": url\n",
    "        }\n",
    "\n",
    "        for location in locations:\n",
    "            location_lat = location[\"coordinates\"][0]\n",
    "            location_lon = location[\"coordinates\"][1]\n",
    "            distance = calculate_distance(location_lat, location_lon, event_lat, event_lon)\n",
    "            if alert_level == \"Green\" and distance < 100:\n",
    "                result_json[\"locations_affected\"].append(location)\n",
    "            elif alert_level == \"Orange\" and distance < 1000:\n",
    "                result_json[\"locations_affected\"].append(location)\n",
    "            elif alert_level == \"Red\" < 10000:\n",
    "                result_json[\"locations_affected\"].append(location)\n",
    "                \n",
    "        # Only add disasters that are affecting specified locations\n",
    "        if len(result_json[\"locations_affected\"]) > 0:\n",
    "            result_data.append(result_json)\n",
    "    return result_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fetch disaster data (expensive cell ðŸ¥²)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 450,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_disaster_data_for_locations(locations):\n",
    "    url = \"https://www.gdacs.org/xml/rss.xml\"\n",
    "    response = requests.get(url)\n",
    "    content_xml = response.content.decode(\"utf-8\")\n",
    "    return parse_xml(content_xml, locations, url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 451,
   "metadata": {},
   "outputs": [],
   "source": [
    "locations = [q[\"location\"] for q in QUERIES]\n",
    "DISASTER_DATA = fetch_disaster_data_for_locations(locations)\n",
    "\n",
    "with open(\"data/disaster-data.json\", 'w') as json_file:\n",
    "        json.dump(DISASTER_DATA, json_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Turn disaster data into similar objects as news"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 452,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_articles_for_disaster(disaster):\n",
    "    # generates articles for each location affected by a single disaster\n",
    "    articles = []\n",
    "    for location in disaster[\"locations_affected\"]:\n",
    "\n",
    "        event = \"natural disaster\"\n",
    "        articles.append(\n",
    "            {\n",
    "                \"location\": location,\n",
    "                \"event\": event,\n",
    "                \"name\": disaster[\"title\"],\n",
    "                \"url\": disaster[\"url\"],\n",
    "                \"description\": disaster[\"description\"],\n",
    "                \"timestamp\": disaster[\"timestamp\"]\n",
    "            }\n",
    "        )\n",
    "    return articles\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 453,
   "metadata": {},
   "outputs": [],
   "source": [
    "DISASTER_ARTICLES = []\n",
    "for disaster in DISASTER_DATA:\n",
    "    DISASTER_ARTICLES.extend(generate_articles_for_disaster(disaster))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 454,
   "metadata": {},
   "outputs": [],
   "source": [
    "COMBINED_ARTICLES = DISASTER_ARTICLES + ALL_ARTICLES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 455,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "\n",
    "openai_client = OpenAI(api_key=OPENAI_API_KEY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 456,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_location_name(location):\n",
    "    return f\"{location['city']}, {location['country']}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 457,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_system_prompt(location):\n",
    "    location_name = parse_location_name(location)\n",
    "    return f\"\"\"\n",
    "You're an analyst for Outokumpu, a stainless steel manufacturer.\n",
    "You're tasked with monitoring news articles for events that could impact the company's operations.\n",
    "You have an important raw material supplier in {location_name}.\n",
    "You monitor news articles for potentially disruptive events in {location_name}.\n",
    "If there is an event that could impact the company's operations, you need to mention it in your report.\n",
    "If the news don't contain important information, you MUST NOT mention it in your daily report.\n",
    "For important information, the location must match {location_name} and the event must be important.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 458,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_articles_for_location(location, articles, max_per_event=5):\n",
    "    location_name = parse_location_name(location)\n",
    "    return [a for a in articles if parse_location_name(a[\"location\"]) == location_name][:max_per_event]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 459,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_query_prompt(articles):\n",
    "    prompt = \"\"\n",
    "    for article in articles:\n",
    "        prompt += f\"\"\"\n",
    "        Title: {article[\"name\"]}\n",
    "        Description: {article[\"description\"]}\n",
    "        URL: {article[\"url\"]}\n",
    "        \"\"\"\n",
    "    return prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 460,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tool_for_location(location):\n",
    "    location_name = parse_location_name(location)\n",
    "    return [\n",
    "        {\n",
    "            \"type\": \"function\",\n",
    "            \"function\": {\n",
    "                \"name\": \"report_risk_status\",\n",
    "                \"description\": f\"Report the risk status for {location_name} based on the news articles\",\n",
    "                \"parameters\": {\n",
    "                    \"type\": \"object\",\n",
    "                    \"properties\": {\n",
    "                        \"has_risk\": {\n",
    "                            \"type\": \"boolean\",\n",
    "                            \"description\": \"Whether there is a potential risk for operations or not\",\n",
    "                        },\n",
    "                        \"risk_title\": {\n",
    "                            \"type\": \"string\",\n",
    "                            \"description\": \"Given if there is a risk. One sentence title for the risk for operations intended for analysts. For example: Potential disruption due to a labor strike in the region.\",\n",
    "                        },\n",
    "                        \"risk_summary\": {\n",
    "                            \"type\": \"string\",\n",
    "                            \"description\": \"Given if there is a risk. A few sentences summary for the risk for operations intended for analysts.\",\n",
    "                        },\n",
    "                        \"articles\": {\n",
    "                            \"type\": \"array\",\n",
    "                            \"description\": \"Given if there is a risk. The articles that support the risk.\",\n",
    "                            \"items\": {\n",
    "                                \"type\": \"object\",\n",
    "                                \"properties\": {\n",
    "                                    \"title\": {\n",
    "                                        \"type\": \"string\",\n",
    "                                        \"description\": \"The title of the article\",\n",
    "                                    },\n",
    "                                    \"content\": {\n",
    "                                        \"type\": \"string\",\n",
    "                                        \"description\": \"The content of the article\",\n",
    "                                    },\n",
    "                                    \"url\": {\n",
    "                                        \"type\": \"string\",\n",
    "                                        \"description\": \"The URL of the article\",\n",
    "                                    },\n",
    "                                },\n",
    "                            },\n",
    "                        },\n",
    "                    },\n",
    "                    \"required\": [\"has_risk\"],\n",
    "                },\n",
    "            },\n",
    "        },\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 461,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_prompts_for_location(location, articles):\n",
    "    query_prompt = get_query_prompt(articles)\n",
    "    system_prompt = get_system_prompt(location)\n",
    "    tools = get_tool_for_location(location)\n",
    "    return {\n",
    "        \"messages\": [\n",
    "            {\n",
    "                \"role\": \"system\",\n",
    "                \"content\": system_prompt,\n",
    "            },\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": query_prompt,\n",
    "            },\n",
    "        ],\n",
    "        \"tools\": tools,\n",
    "        \"tool_choice\": {\"type\": \"function\", \"function\": {\"name\": \"report_risk_status\"}},\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 462,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_completion_for_location(location, articles):\n",
    "    articles = get_articles_for_location(location, articles)\n",
    "    prompts = get_prompts_for_location(location, articles)\n",
    "    completion = openai.chat.completions.create(\n",
    "        messages=prompts[\"messages\"],\n",
    "        tools=prompts[\"tools\"],\n",
    "        tool_choice=prompts[\"tool_choice\"],\n",
    "        model=MODEL_ID,\n",
    "        max_tokens=500,\n",
    "        temperature=0.3\n",
    "    )\n",
    "    return completion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 463,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_risk_status_from_completion(completion):\n",
    "    try:\n",
    "        return json.loads(completion.choices[0].message.tool_calls[0].function.arguments)\n",
    "    except Exception as e:\n",
    "        print(f\"------\\nError parsing risk status: {e}\")\n",
    "        print(f\"Related completion: {completion}------\\n\")\n",
    "        return { \"has_risk\": False }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 464,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\n",
      "    {\n",
      "        \"location\": {\n",
      "            \"country\": \"Colombia\",\n",
      "            \"city\": \"Bogota\",\n",
      "            \"coordinates\": [\n",
      "                4.678390790414742,\n",
      "                -74.08310452775451\n",
      "            ]\n",
      "        },\n",
      "        \"risk_status\": {\n",
      "            \"has_risk\": false\n",
      "        }\n",
      "    },\n",
      "    {\n",
      "        \"location\": {\n",
      "            \"country\": \"Guatemala\",\n",
      "            \"city\": \"El Estor\",\n",
      "            \"coordinates\": [\n",
      "                15.5322197047923,\n",
      "                -89.33265507494376\n",
      "            ]\n",
      "        },\n",
      "        \"risk_status\": {\n",
      "            \"has_risk\": false\n",
      "        }\n",
      "    },\n",
      "    {\n",
      "        \"location\": {\n",
      "            \"country\": \"Brazil\",\n",
      "            \"city\": \"Onca Puma\",\n",
      "            \"coordinates\": [\n",
      "                -6.605335306591729,\n",
      "                -51.100066887737015\n",
      "            ]\n",
      "        },\n",
      "        \"risk_status\": {\n",
      "            \"has_risk\": false\n",
      "        }\n",
      "    },\n",
      "    {\n",
      "        \"location\": {\n",
      "            \"country\": \"Holland\",\n",
      "            \"city\": \"Terneuzen\",\n",
      "            \"coordinates\": [\n",
      "                51.33013942257549,\n",
      "                3.83565678442852\n",
      "            ]\n",
      "        },\n",
      "        \"risk_status\": {\n",
      "            \"has_risk\": false\n",
      "        }\n",
      "    }\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "risk_statuses = []\n",
    "for query in QUERIES:\n",
    "    completion = get_completion_for_location(query[\"location\"], COMBINED_ARTICLES)\n",
    "    risk_status = parse_risk_status_from_completion(completion)\n",
    "    risk_statuses.append({\n",
    "        \"location\": query[\"location\"],\n",
    "        \"risk_status\": risk_status\n",
    "    })\n",
    "\n",
    "# pretty print the results json\n",
    "print(json.dumps(risk_statuses, indent=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Try adding a fake article of an important risk and see if GPT elevates that"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 465,
   "metadata": {},
   "outputs": [],
   "source": [
    "fake_strike_onca_puma = {\n",
    "    \"location\": {\n",
    "        \"country\": \"Brazil\",\n",
    "        \"city\": \"Onca Puma\",\n",
    "        \"coordinates\": [-6.605335306591729, -51.100066887737015],\n",
    "    },\n",
    "    \"event\": \"workers strike\",\n",
    "    \"name\": \"Factory workers' union calls for strike in Onca Puma\",\n",
    "    \"url\": \"https://fakeurl.com/workers-strike\",\n",
    "    \"description\": \"The union representing mining workers in Onca Puma has called for a strike.\",\n",
    "    \"timestamp\": \"2021-07-25T21:35:00.0000000Z\"\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fetch analysis from GPT for the extended queries (expensive cell ðŸ¥²)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 466,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\n",
      "    {\n",
      "        \"location\": {\n",
      "            \"country\": \"Colombia\",\n",
      "            \"city\": \"Bogota\",\n",
      "            \"coordinates\": [\n",
      "                4.678390790414742,\n",
      "                -74.08310452775451\n",
      "            ]\n",
      "        },\n",
      "        \"risk_status\": {\n",
      "            \"has_risk\": false\n",
      "        }\n",
      "    },\n",
      "    {\n",
      "        \"location\": {\n",
      "            \"country\": \"Guatemala\",\n",
      "            \"city\": \"El Estor\",\n",
      "            \"coordinates\": [\n",
      "                15.5322197047923,\n",
      "                -89.33265507494376\n",
      "            ]\n",
      "        },\n",
      "        \"risk_status\": {\n",
      "            \"has_risk\": false\n",
      "        }\n",
      "    },\n",
      "    {\n",
      "        \"location\": {\n",
      "            \"country\": \"Brazil\",\n",
      "            \"city\": \"Onca Puma\",\n",
      "            \"coordinates\": [\n",
      "                -6.605335306591729,\n",
      "                -51.100066887737015\n",
      "            ]\n",
      "        },\n",
      "        \"risk_status\": {\n",
      "            \"has_risk\": true,\n",
      "            \"risk_title\": \"Potential disruption due to a labor strike in the region\",\n",
      "            \"risk_summary\": \"The union representing mining workers in Onca Puma has called for a strike. This could lead to disruptions in the supply of raw materials for our operations. The strike has the potential to impact production and should be closely monitored.\",\n",
      "            \"articles\": [\n",
      "                {\n",
      "                    \"title\": \"Factory workers' union calls for strike in Onca Puma\",\n",
      "                    \"content\": \"The union representing mining workers in Onca Puma has called for a strike.\",\n",
      "                    \"url\": \"https://fakeurl.com/workers-strike\"\n",
      "                }\n",
      "            ]\n",
      "        }\n",
      "    },\n",
      "    {\n",
      "        \"location\": {\n",
      "            \"country\": \"Holland\",\n",
      "            \"city\": \"Terneuzen\",\n",
      "            \"coordinates\": [\n",
      "                51.33013942257549,\n",
      "                3.83565678442852\n",
      "            ]\n",
      "        },\n",
      "        \"risk_status\": {\n",
      "            \"has_risk\": false\n",
      "        }\n",
      "    }\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "# Put the fake article first because only first 5 articles are considered\n",
    "# per each (event, location) pair\n",
    "extended_articles = [fake_strike_onca_puma] + COMBINED_ARTICLES\n",
    "\n",
    "risk_statuses_extended = []\n",
    "for query in QUERIES:\n",
    "    completion = get_completion_for_location(query[\"location\"], extended_articles)\n",
    "    risk_status = parse_risk_status_from_completion(completion)\n",
    "    risk_statuses_extended.append({\n",
    "        \"location\": query[\"location\"],\n",
    "        \"risk_status\": risk_status\n",
    "    })\n",
    "\n",
    "# pretty print the results json\n",
    "print(json.dumps(risk_statuses_extended, indent=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 467,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dump risk_statuses_extended to a file\n",
    "json.dump(risk_statuses_extended, open(\"data/risk-statuses.json\", \"w\"), indent=4)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
